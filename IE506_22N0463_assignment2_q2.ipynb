{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qq51Ex1TbYjj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from math import sqrt\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(a)}$"
      ],
      "metadata": {
        "id": "-dePyZ1X5s55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$min_{\\beta}   \\ \\lambda \\| \\beta \\|_{2}^2 + \\| y- X\\beta \\|_2^2 = min_{\\beta} \\ Z \\ \\  (say)$\n",
        "\n",
        "let X is of order N x D\n",
        "\n",
        "$Z = \\lambda \\| \\beta \\|_{2}^2 + \\| y- X\\beta \\|_2^2 \\\\ \\Rightarrow \\lambda\\beta^T \\beta   + (y-X\\beta)^T(y-X\\beta)\n",
        "\\\\ \\Rightarrow y^T y - \\beta ^T X^T y + \\beta^T X ^T X \\beta - y^T X \\beta + \\lambda \\beta^T \\beta$\n",
        "\n",
        "To find the optimal weight vector $\\boldsymbol{\\beta}$, we take the derivative of the cost function with respect to $\\boldsymbol{\\beta}$ and set it to zero\n",
        "\n",
        "$\\Rightarrow 2X^T X \\beta -2X^Ty +2\\lambda \\beta =0 \\\\ \\Rightarrow X^TX\\beta + \\lambda \\beta = X^Ty \\ \\  \\ \\ \\ \\  ....(1)$\n",
        " $ or X^TX\\beta -X^Ty=-\\lambda \\beta  \n",
        "\\\\ \\Rightarrow \\beta = \\frac{1}{\\lambda} X^T(y-X\\beta) \\\\ so \\  \\beta \\  can \\  be  \\ written \\  as \\\\ \\beta= X^T \\alpha \\ \\ \\ \\   ...(2) \\ where \\ \\ \\alpha = \\frac{1}{\\lambda} (y-X\\beta) \\\\ \n",
        "now \\   we  \\ can \\  write \\  (1) \\  as \\  \n",
        " \\\\ \\beta=(X^T X + \\lambda I_{D})^{-1} X^T y\n",
        " \\\\ \\Rightarrow \\beta = X^T(X X^T + \\lambda I_{N})^{-1}y  \\ \\ \\ ..(3) \\  by \\  matrix  \\ inversion \\  lemma \\\\\n",
        "  \\ comparing  \\ (2)  \\  and \\  (3)  \\ we \\ got \\ \\\\ \\alpha = (X X^T + \\lambda I_{N})^{-1}y \\\\ now  \\ in \\  this \\  relation  \\ X^TX  \\ \\text{can be effectively replace by a kernel matrix using the kernel function let k as kernel } \\\\ \n",
        "  \\alpha = (K + \\lambda I_N)^{-1}y\n",
        "  \\\\ \\text{then we can rewrite} \\ \\beta \\ as \\ \n",
        "  \\\\ \\beta=X^T \\alpha = \\sum_{i=1}^{i=N} \n",
        "\\alpha_i X_i \\\\   \\text{This tells us that the solution vector is just a linear sum of the N training vectors. When we plug this in at test time to compute the predictive mean},\\\\ \\text{let's compute for a sample} \\  x̃  \\\\  \\\\  ỹ(x̃) = \\beta^Tx̃ = \\sum_{i=1}^{i=N} \\alpha_i x_i^Tx̃ = \\sum_{i=1}^{i=N} \\alpha_i K(x̃,x_i)$"
      ],
      "metadata": {
        "id": "SaxvJ3r7qiVL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(b)}$"
      ],
      "metadata": {
        "id": "yr2if9hl5yev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Data_Q2.csv')"
      ],
      "metadata": {
        "id": "KSOkAVlTqG4X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wvVKGNg4vaE8",
        "outputId": "6ca502c3-bff3-40bc-b21e-c0455062c713"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Temperature  Humidity  Wind Speed   Flow  Consumption\n",
              "0        5.578     93.00       0.082  0.185  5935.174070\n",
              "1       15.510     64.38       0.085  0.133  6044.657863\n",
              "2       15.730     64.21       0.084  0.152  6061.944778\n",
              "3       15.620     65.22       0.083  0.145  6108.043217\n",
              "4       15.450     67.69       0.083  0.189  6119.567827"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-824429d4-2221-47e5-9ec3-c165bcd01d07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind Speed</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Consumption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.578</td>\n",
              "      <td>93.00</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.185</td>\n",
              "      <td>5935.174070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.510</td>\n",
              "      <td>64.38</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.133</td>\n",
              "      <td>6044.657863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.730</td>\n",
              "      <td>64.21</td>\n",
              "      <td>0.084</td>\n",
              "      <td>0.152</td>\n",
              "      <td>6061.944778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15.620</td>\n",
              "      <td>65.22</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.145</td>\n",
              "      <td>6108.043217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.450</td>\n",
              "      <td>67.69</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.189</td>\n",
              "      <td>6119.567827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-824429d4-2221-47e5-9ec3-c165bcd01d07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-824429d4-2221-47e5-9ec3-c165bcd01d07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-824429d4-2221-47e5-9ec3-c165bcd01d07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(c)}$"
      ],
      "metadata": {
        "id": "b-6Dtivd51tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd = StandardScaler()\n",
        "df_scaled = pd.DataFrame(sd.fit_transform(df), columns = df.columns)"
      ],
      "metadata": {
        "id": "k0zeap6eybE2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "szFVQ3hrzuMX",
        "outputId": "33ce48f3-8ef8-4b0b-b220-0d96831418b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Temperature  Humidity  Wind Speed      Flow  Consumption\n",
              "0    -1.931878  1.404846   -0.641791 -0.664370    -3.450208\n",
              "1     0.407654 -0.874474   -0.640417 -0.665724    -3.282442\n",
              "2     0.459476 -0.888013   -0.640875 -0.665229    -3.255953\n",
              "3     0.433565 -0.807575   -0.641333 -0.665412    -3.185315\n",
              "4     0.393521 -0.610863   -0.641333 -0.664266    -3.167655"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e3c3c09-6af7-4613-952a-8c64ff179fd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind Speed</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Consumption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.931878</td>\n",
              "      <td>1.404846</td>\n",
              "      <td>-0.641791</td>\n",
              "      <td>-0.664370</td>\n",
              "      <td>-3.450208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.407654</td>\n",
              "      <td>-0.874474</td>\n",
              "      <td>-0.640417</td>\n",
              "      <td>-0.665724</td>\n",
              "      <td>-3.282442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.459476</td>\n",
              "      <td>-0.888013</td>\n",
              "      <td>-0.640875</td>\n",
              "      <td>-0.665229</td>\n",
              "      <td>-3.255953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.433565</td>\n",
              "      <td>-0.807575</td>\n",
              "      <td>-0.641333</td>\n",
              "      <td>-0.665412</td>\n",
              "      <td>-3.185315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.393521</td>\n",
              "      <td>-0.610863</td>\n",
              "      <td>-0.641333</td>\n",
              "      <td>-0.664266</td>\n",
              "      <td>-3.167655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e3c3c09-6af7-4613-952a-8c64ff179fd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e3c3c09-6af7-4613-952a-8c64ff179fd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e3c3c09-6af7-4613-952a-8c64ff179fd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_scaled['Consumption']\n",
        "X = df_scaled.drop(['Consumption'], axis=1)"
      ],
      "metadata": {
        "id": "kQZFwlUM2TyD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HZ1pDd4s36uL",
        "outputId": "3c6ad50f-4659-4f47-c294-e88f6fad5878"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Temperature  Humidity  Wind Speed      Flow\n",
              "0    -1.931878  1.404846   -0.641791 -0.664370\n",
              "1     0.407654 -0.874474   -0.640417 -0.665724\n",
              "2     0.459476 -0.888013   -0.640875 -0.665229\n",
              "3     0.433565 -0.807575   -0.641333 -0.665412\n",
              "4     0.393521 -0.610863   -0.641333 -0.664266"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ff61d75-6fb8-4dc6-8ec5-b06973477cc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind Speed</th>\n",
              "      <th>Flow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.931878</td>\n",
              "      <td>1.404846</td>\n",
              "      <td>-0.641791</td>\n",
              "      <td>-0.664370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.407654</td>\n",
              "      <td>-0.874474</td>\n",
              "      <td>-0.640417</td>\n",
              "      <td>-0.665724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.459476</td>\n",
              "      <td>-0.888013</td>\n",
              "      <td>-0.640875</td>\n",
              "      <td>-0.665229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.433565</td>\n",
              "      <td>-0.807575</td>\n",
              "      <td>-0.641333</td>\n",
              "      <td>-0.665412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.393521</td>\n",
              "      <td>-0.610863</td>\n",
              "      <td>-0.641333</td>\n",
              "      <td>-0.664266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ff61d75-6fb8-4dc6-8ec5-b06973477cc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ff61d75-6fb8-4dc6-8ec5-b06973477cc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ff61d75-6fb8-4dc6-8ec5-b06973477cc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL_6Ar9339hF",
        "outputId": "ab80fa9a-477f-4904-dd53-fbbb397e7c29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   -3.450208\n",
              "1   -3.282442\n",
              "2   -3.255953\n",
              "3   -3.185315\n",
              "4   -3.167655\n",
              "Name: Consumption, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(d)}$"
      ],
      "metadata": {
        "id": "GwcxupTK54iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, x_test, y_train,  y_test = train_test_split(X, y, random_state=104, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "-gcZt2B_0F2e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*where X_train and y_train belongs to set T1(80% of the original dataset) and x_test and y_test belongs to set T2(20% of the original dataset)*"
      ],
      "metadata": {
        "id": "OHsBU2lAEhlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T1 = pd.DataFrame(X_train.copy())\n",
        "T1.insert(4, 'Consumption', y_train)\n",
        "T1['Consumption'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEhQBpHtF4YA",
        "outputId": "dc59e604-ab10-4a39-b93b-bfd88eb02e69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.779256    6\n",
              "-0.156700    5\n",
              " 0.003278    5\n",
              " 0.796916    5\n",
              " 0.637980    5\n",
              "            ..\n",
              "-0.810104    1\n",
              "-1.852018    1\n",
              " 0.716846    1\n",
              "-0.839148    1\n",
              "-0.677657    1\n",
              "Name: Consumption, Length: 525, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T2 = pd.DataFrame(x_test.copy())\n",
        "T2.insert(4, 'Consumption', y_test)\n",
        "T2['Consumption'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgwg0rjTItuK",
        "outputId": "be242c09-a7a0-4c76-e0f9-331cf272a84a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.609536    3\n",
              " 0.090533    3\n",
              " 0.646809    3\n",
              " 0.099814    2\n",
              " 0.593831    2\n",
              "            ..\n",
              " 0.626873    1\n",
              "-1.260423    1\n",
              " 0.814575    1\n",
              " 0.579288    1\n",
              "-0.120786    1\n",
              "Name: Consumption, Length: 179, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear from the above result that T1 and T2 don't have similar counts in Consumption column."
      ],
      "metadata": {
        "id": "qFwoJVRSL8dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(e)}$"
      ],
      "metadata": {
        "id": "KEJiJta45mpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(KernelRidge(kernel='rbf'))\n",
        "param_range = np.linspace(0.1,100,30)\n",
        "train_scores, val_scores = validation_curve(estimator=pipeline,X=X_train, y=y_train,cv=5,n_jobs=-1,param_name='kernelridge__gamma', param_range=param_range)\n",
        "#print('train scores:',train_scores)\n",
        "#print('val scores:',val_scores)\n",
        "\n",
        "print('Printing more details of scores for each alpha:')\n",
        "for i in range(len(param_range)):\n",
        "  print('alpha:', param_range[i])\n",
        "  print('train scores:', train_scores[i])\n",
        "  print('val scores:', val_scores[i])\n",
        "  print('**************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfhu_dXe5S-M",
        "outputId": "31026478-3332-423d-c28d-13f2320044ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.17445777 0.19089983 0.18473138 0.1523181  0.17574001]\n",
            "val scores: [0.12064416 0.03828975 0.11118193 0.22128271 0.12438234]\n",
            "**************************\n",
            "alpha: 3.544827586206897\n",
            "train scores: [0.45991592 0.49020863 0.47481266 0.45467279 0.45449288]\n",
            "val scores: [0.15949097 0.06113524 0.10533498 0.26190812 0.22834725]\n",
            "**************************\n",
            "alpha: 6.989655172413793\n",
            "train scores: [0.55296314 0.57693166 0.56060645 0.55241684 0.54188563]\n",
            "val scores: [0.20935224 0.08958941 0.15161923 0.26410426 0.24883065]\n",
            "**************************\n",
            "alpha: 10.43448275862069\n",
            "train scores: [0.60109208 0.6163382  0.60446175 0.59837107 0.58262403]\n",
            "val scores: [0.21417169 0.10921437 0.16788563 0.27036072 0.25597302]\n",
            "**************************\n",
            "alpha: 13.879310344827587\n",
            "train scores: [0.62903424 0.63775292 0.62950334 0.62427705 0.60687575]\n",
            "val scores: [0.20545073 0.12373169 0.17301499 0.27105924 0.25545956]\n",
            "**************************\n",
            "alpha: 17.324137931034485\n",
            "train scores: [0.64682334 0.65116873 0.64518068 0.64093379 0.6235145 ]\n",
            "val scores: [0.19451463 0.13381763 0.1739069  0.26822775 0.25091606]\n",
            "**************************\n",
            "alpha: 20.768965517241384\n",
            "train scores: [0.65913425 0.66046219 0.65591809 0.6527231  0.63593336]\n",
            "val scores: [0.18417193 0.14038947 0.17276531 0.26360458 0.24475278]\n",
            "**************************\n",
            "alpha: 24.21379310344828\n",
            "train scores: [0.66827706 0.66742697 0.66388313 0.66170629 0.64577574]\n",
            "val scores: [0.17508466 0.14467948 0.17057545 0.25824286 0.23820406]\n",
            "**************************\n",
            "alpha: 27.658620689655177\n",
            "train scores: [0.67545189 0.67297522 0.67017874 0.66893284 0.653914  ]\n",
            "val scores: [0.16731309 0.14760138 0.16783958 0.25270107 0.23181594]\n",
            "**************************\n",
            "alpha: 31.103448275862075\n",
            "train scores: [0.68131908 0.67759953 0.6753911  0.67497063 0.66083791]\n",
            "val scores: [0.16072311 0.14970527 0.16482205 0.24725504 0.22580157]\n",
            "**************************\n",
            "alpha: 34.54827586206897\n",
            "train scores: [0.68626452 0.68158043 0.67984855 0.6801472  0.66684035]\n",
            "val scores: [0.15512771 0.15129643 0.16166803 0.24203253 0.22022491]\n",
            "**************************\n",
            "alpha: 37.99310344827587\n",
            "train scores: [0.69052743 0.68508646 0.68374651 0.68466499 0.67210991]\n",
            "val scores: [0.15034317 0.15254    0.1584635  0.23708603 0.2150856 ]\n",
            "**************************\n",
            "alpha: 41.437931034482766\n",
            "train scores: [0.69426449 0.68822449 0.68720889 0.68865815 0.67677752]\n",
            "val scores: [0.14620964 0.1535264  0.1552644  0.23243009 0.21035683]\n",
            "**************************\n",
            "alpha: 44.882758620689664\n",
            "train scores: [0.69758342 0.69106595 0.69031924 0.69222132 0.6809402 ]\n",
            "val scores: [0.14259602 0.15430752 0.15211022 0.22806027 0.20600232]\n",
            "**************************\n",
            "alpha: 48.327586206896555\n",
            "train scores: [0.70056141 0.69366095 0.693137   0.69542486 0.68467351]\n",
            "val scores: [0.13939816 0.15491574 0.1490302  0.22396279 0.20198412]\n",
            "**************************\n",
            "alpha: 51.77241379310345\n",
            "train scores: [0.70325566 0.69604623 0.6957065  0.69832317 0.68803827]\n",
            "val scores: [0.13653478 0.15537356 0.14604619 0.22011974 0.19826608]\n",
            "**************************\n",
            "alpha: 55.21724137931035\n",
            "train scores: [0.70570979 0.69824977 0.69806203 0.70095956 0.6910845 ]\n",
            "val scores: [0.13394298 0.15569836 0.14317414 0.21651171 0.19481539]\n",
            "**************************\n",
            "alpha: 58.66206896551725\n",
            "train scores: [0.70795783 0.7002936  0.70023093 0.70336918 0.69385383]\n",
            "val scores: [0.13157424 0.1559046  0.1404251  0.21311939 0.191603  ]\n",
            "**************************\n",
            "alpha: 62.10689655172415\n",
            "train scores: [0.71002685 0.70219553 0.70223548 0.70558099 0.69638126]\n",
            "val scores: [0.12939105 0.15600493 0.13780595 0.20992429 0.18860356]\n",
            "**************************\n",
            "alpha: 65.55172413793103\n",
            "train scores: [0.7119388  0.70397029 0.7040942  0.70761911 0.69869632]\n",
            "val scores: [0.12736427 0.15601063 0.1353201  0.20690921 0.18579511]\n",
            "**************************\n",
            "alpha: 68.99655172413793\n",
            "train scores: [0.71371167 0.70563034 0.70582269 0.70950379 0.70082411]\n",
            "val scores: [0.12547107 0.15593184 0.13296822 0.20405838 0.18315867]\n",
            "**************************\n",
            "alpha: 72.44137931034483\n",
            "train scores: [0.7153605  0.70718632 0.70743424 0.71125217 0.70278601]\n",
            "val scores: [0.12369338 0.15577774 0.13074877 0.2013575  0.18067781]\n",
            "**************************\n",
            "alpha: 75.88620689655173\n",
            "train scores: [0.71689797 0.7086475  0.70894028 0.71287883 0.70460032]\n",
            "val scores: [0.12201673 0.15555654 0.12865853 0.19879369 0.17833827]\n",
            "**************************\n",
            "alpha: 79.33103448275862\n",
            "train scores: [0.71833488 0.71002199 0.71035074 0.7143963  0.70628279]\n",
            "val scores: [0.12042941 0.15527565 0.12669307 0.19635541 0.17612759]\n",
            "**************************\n",
            "alpha: 82.77586206896552\n",
            "train scores: [0.71968058 0.71131697 0.71167426 0.71581535 0.70784701]\n",
            "val scores: [0.11892178 0.15494171 0.12484711 0.19403231 0.17403485]\n",
            "**************************\n",
            "alpha: 86.22068965517242\n",
            "train scores: [0.72094318 0.71253882 0.71291846 0.71714535 0.70930478]\n",
            "val scores: [0.11748581 0.15456066 0.12311482 0.19181515 0.17205039]\n",
            "**************************\n",
            "alpha: 89.66551724137932\n",
            "train scores: [0.72212979 0.71369326 0.71409006 0.71839445 0.71066636]\n",
            "val scores: [0.11611475 0.15413785 0.12149006 0.18969564 0.17016563]\n",
            "**************************\n",
            "alpha: 93.1103448275862\n",
            "train scores: [0.72324672 0.71478545 0.715195   0.71956982 0.71194075]\n",
            "val scores: [0.11480283 0.15367807 0.11996655 0.18766634 0.16837289]\n",
            "**************************\n",
            "alpha: 96.5551724137931\n",
            "train scores: [0.72429955 0.71582002 0.71623861 0.72067776 0.71313586]\n",
            "val scores: [0.11354507 0.1531856  0.11853802 0.18572055 0.16666525]\n",
            "**************************\n",
            "alpha: 100.0\n",
            "train scores: [0.72529327 0.71680119 0.71722563 0.72172387 0.71425865]\n",
            "val scores: [0.11233713 0.15266431 0.11719833 0.18385225 0.16503645]\n",
            "**************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_train_scores = np.mean(train_scores,axis=1)\n",
        "avg_val_scores = np.mean(val_scores,axis=1)\n",
        "print('average train scores :',avg_train_scores)\n",
        "print('average val scores :',avg_val_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_dpKRzy6QVr",
        "outputId": "611150f3-f117-4c41-83cc-2505eeab26b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average train scores : [0.17562942 0.46682058 0.55696074 0.60057743 0.62548866 0.64152421\n",
            " 0.6528342  0.66141384 0.66829054 0.67402365 0.67893621 0.68322706\n",
            " 0.68702671 0.69042602 0.69349154 0.69627397 0.69881313 0.70114107\n",
            " 0.70328402 0.70526374 0.70709852 0.70880385 0.71039298 0.71187734\n",
            " 0.71326683 0.71457012 0.71579478 0.71694755 0.71803436 0.71906052]\n",
            "average val scores : [0.12315618 0.16324331 0.19269916 0.20352109 0.20574324 0.2042766\n",
            " 0.20113681 0.1973573  0.19345421 0.18966141 0.18606992 0.18270366\n",
            " 0.17955748 0.17661527 0.1738582  0.17126807 0.16882852 0.16652527\n",
            " 0.16434596 0.16227986 0.16031764 0.15845104 0.15667275 0.15497622\n",
            " 0.15335555 0.15180537 0.15032079 0.14889733 0.1475309  0.14621769]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha = param_range[np.argmax(avg_val_scores)]\n",
        "print('best_hyper_parameter from 5 fold CV:',best_alpha)\n",
        "kernel = KernelRidge(kernel='rbf',gamma=best_alpha)\n",
        "\n",
        "kernel.fit(X_train, y_train)\n",
        "y_pred_train = kernel.predict(X_train)\n",
        "y_pred_test = kernel.predict(x_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXZ-VIvs8xZH",
        "outputId": "cf481490-1614-4c1b-be25-32d1533242db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_hyper_parameter from 5 fold CV: 13.879310344827587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(f)}$"
      ],
      "metadata": {
        "id": "1AiYtZXb-5kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"rmse_train:\", sqrt(mean_squared_error(y_train, y_pred_train)))\n",
        "print(\"r_2_train:\",r2_score(y_train, y_pred_train))\n",
        "print(\"rmse_test:\", sqrt(mean_squared_error(y_test, y_pred_test)))\n",
        "print('r_2_test',r2_score(y_test,y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh8mbfu-9INB",
        "outputId": "f9b7c8fd-1b5c-45ff-9eb0-ec9665c2bb43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmse_train: 0.6140862315539782\n",
            "r_2_train: 0.6207767986432727\n",
            "rmse_test: 0.8877996925168121\n",
            "r_2_test 0.2206201979680208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(g)}$"
      ],
      "metadata": {
        "id": "VTOs7fbM_DxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2 = pd.read_csv('Data_Q2.csv')\n",
        "\n",
        "frame2.loc[frame2['Consumption'] <= 6500, 'Class'] = 1\n",
        "frame2.loc[(frame2['Consumption'] > 6500) & (frame2['Consumption'] <= 7000), 'Class'] = 2\n",
        "frame2.loc[(frame2['Consumption'] > 7000) & (frame2['Consumption'] <= 7500), 'Class'] = 3\n",
        "frame2.loc[(frame2['Consumption'] > 7500) & (frame2['Consumption'] <= 8000), 'Class'] = 4\n",
        "frame2.loc[(frame2['Consumption'] > 8000) & (frame2['Consumption'] <= 8500), 'Class'] = 5\n",
        "frame2.loc[(frame2['Consumption'] > 8500) & (frame2['Consumption'] <= 9000), 'Class'] = 6\n",
        "frame2.loc[frame2['Consumption'] > 9000 , 'Class'] = 7"
      ],
      "metadata": {
        "id": "hoJvfWFD-YWf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sSiiwqDd_eiX",
        "outputId": "40d90374-bf8e-4dbd-f7e2-e5381a995d57"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Temperature  Humidity  Wind Speed     Flow  Consumption  Class\n",
              "0          5.578     93.00       0.082    0.185  5935.174070    1.0\n",
              "1         15.510     64.38       0.085    0.133  6044.657863    1.0\n",
              "2         15.730     64.21       0.084    0.152  6061.944778    1.0\n",
              "3         15.620     65.22       0.083    0.145  6108.043217    1.0\n",
              "4         15.450     67.69       0.083    0.189  6119.567827    1.0\n",
              "..           ...       ...         ...      ...          ...    ...\n",
              "995       17.330     42.24       4.917   31.540  9443.855422    7.0\n",
              "996        7.010     76.40       4.920   65.890  9449.638554    7.0\n",
              "997       14.810     82.30       4.913    0.159  9449.638554    7.0\n",
              "998       12.090     77.40       0.073    0.104  9449.638554    7.0\n",
              "999       16.680     64.92       0.079  112.400  9449.990000    7.0\n",
              "\n",
              "[1000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37d27b4a-581d-4466-9897-995fa8d4c420\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind Speed</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Consumption</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.578</td>\n",
              "      <td>93.00</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.185</td>\n",
              "      <td>5935.174070</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.510</td>\n",
              "      <td>64.38</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.133</td>\n",
              "      <td>6044.657863</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.730</td>\n",
              "      <td>64.21</td>\n",
              "      <td>0.084</td>\n",
              "      <td>0.152</td>\n",
              "      <td>6061.944778</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15.620</td>\n",
              "      <td>65.22</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.145</td>\n",
              "      <td>6108.043217</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.450</td>\n",
              "      <td>67.69</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.189</td>\n",
              "      <td>6119.567827</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>17.330</td>\n",
              "      <td>42.24</td>\n",
              "      <td>4.917</td>\n",
              "      <td>31.540</td>\n",
              "      <td>9443.855422</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>7.010</td>\n",
              "      <td>76.40</td>\n",
              "      <td>4.920</td>\n",
              "      <td>65.890</td>\n",
              "      <td>9449.638554</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>14.810</td>\n",
              "      <td>82.30</td>\n",
              "      <td>4.913</td>\n",
              "      <td>0.159</td>\n",
              "      <td>9449.638554</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>12.090</td>\n",
              "      <td>77.40</td>\n",
              "      <td>0.073</td>\n",
              "      <td>0.104</td>\n",
              "      <td>9449.638554</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>16.680</td>\n",
              "      <td>64.92</td>\n",
              "      <td>0.079</td>\n",
              "      <td>112.400</td>\n",
              "      <td>9449.990000</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37d27b4a-581d-4466-9897-995fa8d4c420')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37d27b4a-581d-4466-9897-995fa8d4c420 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37d27b4a-581d-4466-9897-995fa8d4c420');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(h)}$"
      ],
      "metadata": {
        "id": "as5e_OL6_8O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of unique class labels\n",
        "class_labels = frame2['Class'].unique()\n",
        "\n",
        "# Standardize each subset separately\n",
        "for label in class_labels:\n",
        "    subset = frame2[frame2['Class'] == label].copy()\n",
        "    subset_mean = subset.drop('Class', axis=1).mean()\n",
        "    subset_std = subset.drop('Class', axis=1).std()\n",
        "    subset.loc[:, subset.columns != 'Class'] = (subset.loc[:, subset.columns != 'Class'] - subset_mean) / subset_std\n",
        "    frame2.loc[frame2['Class'] == label, subset.columns] = subset\n",
        "\n",
        "# Save the standardized dataframe\n",
        "frame2.to_csv('frame2_standardized.csv', index=False)"
      ],
      "metadata": {
        "id": "cqru-ApvANtB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BlMu59gBDdd3",
        "outputId": "5e73cdf3-0d4d-41db-dba6-4feafe8dc041"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Temperature  Humidity  Wind Speed      Flow  Consumption  Class\n",
              "0      -1.633251  1.510316   -0.491477 -0.353228    -1.860482    1.0\n",
              "1       1.046563 -1.473479    0.561688 -0.398291    -1.259987    1.0\n",
              "2       1.105922 -1.491202    0.210633 -0.381826    -1.165172    1.0\n",
              "3       1.076242 -1.385904   -0.140422 -0.387892    -0.912332    1.0\n",
              "4       1.030374 -1.128393   -0.140422 -0.349762    -0.849122    1.0\n",
              "..           ...       ...         ...       ...          ...    ...\n",
              "995     0.569285 -2.345601    1.577694 -0.112411     1.703543    7.0\n",
              "996    -1.974412  0.414453    1.579064  0.550097     1.744723    7.0\n",
              "997    -0.051851  0.891161    1.575868 -0.717656     1.744723    7.0\n",
              "998    -0.722282  0.495251   -0.633634 -0.718717     1.744723    7.0\n",
              "999     0.409071 -0.513106   -0.630895  1.447134     1.747225    7.0\n",
              "\n",
              "[1000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b69daedf-7712-4d94-b3e7-3f54209cb504\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind Speed</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Consumption</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.633251</td>\n",
              "      <td>1.510316</td>\n",
              "      <td>-0.491477</td>\n",
              "      <td>-0.353228</td>\n",
              "      <td>-1.860482</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.046563</td>\n",
              "      <td>-1.473479</td>\n",
              "      <td>0.561688</td>\n",
              "      <td>-0.398291</td>\n",
              "      <td>-1.259987</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.105922</td>\n",
              "      <td>-1.491202</td>\n",
              "      <td>0.210633</td>\n",
              "      <td>-0.381826</td>\n",
              "      <td>-1.165172</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.076242</td>\n",
              "      <td>-1.385904</td>\n",
              "      <td>-0.140422</td>\n",
              "      <td>-0.387892</td>\n",
              "      <td>-0.912332</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.030374</td>\n",
              "      <td>-1.128393</td>\n",
              "      <td>-0.140422</td>\n",
              "      <td>-0.349762</td>\n",
              "      <td>-0.849122</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.569285</td>\n",
              "      <td>-2.345601</td>\n",
              "      <td>1.577694</td>\n",
              "      <td>-0.112411</td>\n",
              "      <td>1.703543</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-1.974412</td>\n",
              "      <td>0.414453</td>\n",
              "      <td>1.579064</td>\n",
              "      <td>0.550097</td>\n",
              "      <td>1.744723</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-0.051851</td>\n",
              "      <td>0.891161</td>\n",
              "      <td>1.575868</td>\n",
              "      <td>-0.717656</td>\n",
              "      <td>1.744723</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-0.722282</td>\n",
              "      <td>0.495251</td>\n",
              "      <td>-0.633634</td>\n",
              "      <td>-0.718717</td>\n",
              "      <td>1.744723</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.409071</td>\n",
              "      <td>-0.513106</td>\n",
              "      <td>-0.630895</td>\n",
              "      <td>1.447134</td>\n",
              "      <td>1.747225</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b69daedf-7712-4d94-b3e7-3f54209cb504')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b69daedf-7712-4d94-b3e7-3f54209cb504 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b69daedf-7712-4d94-b3e7-3f54209cb504');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(i)}$"
      ],
      "metadata": {
        "id": "XM_DffDxQnDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T3_X, T4_X, T3_y, T4_y = train_test_split(frame2.iloc[:,:-1],frame2.iloc[:,-1], test_size=0.2,stratify=frame2.iloc[:,-1], random_state=104)"
      ],
      "metadata": {
        "id": "YD3zvLLKQ18p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Class 1 sample in T3_y:', len([label for label in T3_y if label==1]))\n",
        "print('Class 2 sample in T3_y:', len([label for label in T3_y if label==2]))\n",
        "print('Class 3 sample in T3_y:', len([label for label in T3_y if label==3]))\n",
        "print('Class 4 sample in T3_y:', len([label for label in T3_y if label==4]))\n",
        "print('Class 5 sample in T3_y:', len([label for label in T3_y if label==5]))\n",
        "print('Class 6 sample in T3_y:', len([label for label in T3_y if label==6]))\n",
        "print('Class 7 sample in T3_y:', len([label for label in T3_y if label==7]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNHrqPzfe1WW",
        "outputId": "a691efd2-99e9-4fa9-b203-8ffd525aa6e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 sample in T3_y: 12\n",
            "Class 2 sample in T3_y: 22\n",
            "Class 3 sample in T3_y: 82\n",
            "Class 4 sample in T3_y: 174\n",
            "Class 5 sample in T3_y: 224\n",
            "Class 6 sample in T3_y: 204\n",
            "Class 7 sample in T3_y: 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE(random_state = 104)\n",
        "T3_X_new, T3_y_new = oversample.fit_resample(T3_X, T3_y)"
      ],
      "metadata": {
        "id": "19L3F-oDgC2b"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Class 1 sample in T3_y:', len([label for label in T3_y_new if label==1]))\n",
        "print('Class 2 sample in T3_y:', len([label for label in T3_y_new if label==2]))\n",
        "print('Class 3 sample in T3_y:', len([label for label in T3_y_new if label==3]))\n",
        "print('Class 4 sample in T3_y:', len([label for label in T3_y_new if label==4]))\n",
        "print('Class 5 sample in T3_y:', len([label for label in T3_y_new if label==5]))\n",
        "print('Class 6 sample in T3_y:', len([label for label in T3_y_new if label==6]))\n",
        "print('Class 7 sample in T3_y:', len([label for label in T3_y_new if label==7]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc5LbRLngW-a",
        "outputId": "2d9ccf5a-9f84-4ce5-efcd-a65f24329b1f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 sample in T3_y: 224\n",
            "Class 2 sample in T3_y: 224\n",
            "Class 3 sample in T3_y: 224\n",
            "Class 4 sample in T3_y: 224\n",
            "Class 5 sample in T3_y: 224\n",
            "Class 6 sample in T3_y: 224\n",
            "Class 7 sample in T3_y: 224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(SVC(kernel='rbf'))\n",
        "param_range = np.linspace(0.1,10,20)\n",
        "train_scores, val_scores = validation_curve(estimator=pipeline, X=T3_X_new.iloc[:,:-1], y=T3_y_new, cv=5,n_jobs=-1, param_name='svc__gamma', param_range=param_range)\n",
        "#print('train scores:',train_scores)\n",
        "#print('val scores:',val_scores)\n",
        "\n",
        "print('Printing more details of scores for each alpha:')\n",
        "for i in range(len(param_range)):\n",
        "  print('alpha:', param_range[i])\n",
        "  print('train scores:', train_scores[i])\n",
        "  print('val scores:', val_scores[i])\n",
        "  print('**************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM9fXsvBQlcz",
        "outputId": "c63fc1c8-00d1-46ee-f25d-732e78a3448b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.3907496  0.36363636 0.38516746 0.39521912 0.35856574]\n",
            "val scores: [0.32484076 0.26433121 0.31528662 0.3514377  0.37060703]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.6523126  0.63955343 0.64832536 0.6310757  0.64063745]\n",
            "val scores: [0.49681529 0.54458599 0.58917197 0.57188498 0.65814696]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.74720893 0.74082935 0.72727273 0.7314741  0.73386454]\n",
            "val scores: [0.57006369 0.63694268 0.64649682 0.62939297 0.72523962]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.78867624 0.79186603 0.76714514 0.77051793 0.77131474]\n",
            "val scores: [0.61146497 0.66878981 0.67515924 0.66134185 0.72204473]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.81419458 0.82057416 0.79904306 0.79840637 0.81115538]\n",
            "val scores: [0.63694268 0.67834395 0.69426752 0.69648562 0.73801917]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.83253589 0.83413078 0.82376396 0.82310757 0.82709163]\n",
            "val scores: [0.63694268 0.68471338 0.68471338 0.69329073 0.75079872]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.8492823  0.85725678 0.85007974 0.84462151 0.84780876]\n",
            "val scores: [0.65286624 0.70063694 0.6910828  0.7028754  0.76038339]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.86443381 0.87719298 0.86204147 0.86294821 0.85816733]\n",
            "val scores: [0.66242038 0.70382166 0.69745223 0.71565495 0.7571885 ]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.87559809 0.88197767 0.87161085 0.87808765 0.8685259 ]\n",
            "val scores: [0.6656051  0.69745223 0.70063694 0.72523962 0.75399361]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.88277512 0.8923445  0.87559809 0.88685259 0.88446215]\n",
            "val scores: [0.66878981 0.69745223 0.71019108 0.73482428 0.76038339]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.8907496  0.89633174 0.8907496  0.89641434 0.89243028]\n",
            "val scores: [0.66878981 0.70063694 0.71019108 0.74760383 0.7571885 ]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.89792663 0.90191388 0.90031898 0.90836653 0.90039841]\n",
            "val scores: [0.66878981 0.71974522 0.71974522 0.73801917 0.76357827]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.90350877 0.90988836 0.90590112 0.91394422 0.91155378]\n",
            "val scores: [0.66878981 0.7133758  0.72611465 0.74440895 0.76996805]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.90909091 0.91547049 0.90988836 0.92191235 0.91314741]\n",
            "val scores: [0.67197452 0.70700637 0.71656051 0.7571885  0.76357827]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.91467305 0.91945774 0.91467305 0.92669323 0.91633466]\n",
            "val scores: [0.67197452 0.70063694 0.71656051 0.76357827 0.77635783]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.92025518 0.92264753 0.91786284 0.9314741  0.92191235]\n",
            "val scores: [0.66242038 0.70382166 0.71656051 0.76677316 0.77635783]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.92424242 0.92982456 0.92264753 0.93545817 0.92350598]\n",
            "val scores: [0.65923567 0.70063694 0.71656051 0.76677316 0.7827476 ]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.92663477 0.93460925 0.92583732 0.93466135 0.92669323]\n",
            "val scores: [0.65605096 0.70063694 0.7133758  0.76677316 0.77955272]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.92822967 0.93620415 0.92743222 0.93944223 0.93306773]\n",
            "val scores: [0.66242038 0.70700637 0.69745223 0.76996805 0.77955272]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.93141946 0.94019139 0.92982456 0.94342629 0.94023904]\n",
            "val scores: [0.65923567 0.70700637 0.70063694 0.76996805 0.7827476 ]\n",
            "**************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_train_scores = np.mean(train_scores,axis=1)\n",
        "avg_val_scores = np.mean(val_scores,axis=1)\n",
        "print('average train scores :',avg_train_scores)\n",
        "print('average val scores :',avg_val_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqYbj5icR9_-",
        "outputId": "f931ae41-33b3-40a0-bff2-5e5fbf8c5411"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average train scores : [0.37866766 0.64238091 0.73612993 0.77790401 0.80867471 0.82812597\n",
            " 0.84980982 0.86495676 0.87516003 0.88440649 0.89333511 0.90178489\n",
            " 0.90895925 0.9139019  0.91836634 0.9228304  0.92713573 0.92968718\n",
            " 0.9328752  0.93702015]\n",
            "average val scores : [0.32530067 0.57212104 0.64162715 0.66776012 0.68881179 0.69009178\n",
            " 0.70156895 0.70730754 0.7085855  0.71432816 0.71688203 0.72197554\n",
            " 0.72453145 0.72326163 0.72582162 0.72518671 0.72519078 0.72327791\n",
            " 0.72327995 0.72391893]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha = param_range[np.argmax(avg_val_scores)]\n",
        "print('best_hyper_parameter from 5 fold CV:',best_alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-txiDJ3SAir",
        "outputId": "33fbf5a1-74e0-4ec8-93e9-56aea52f9838"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_hyper_parameter from 5 fold CV: 7.394736842105264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc_kernel =SVC(kernel='rbf', gamma = best_alpha)\n",
        "\n",
        "svc_kernel.fit(T3_X_new.iloc[:,:-1], T3_y_new)\n",
        "\n",
        "y_pred_train =svc_kernel.predict(T3_X_new.iloc[:,:-1])\n",
        "y_pred_test=svc_kernel.predict(T4_X.iloc[:,:-1])"
      ],
      "metadata": {
        "id": "WSoqf-6JSC-x"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = svc_kernel.score(T3_X_new.iloc[:,:-1], T3_y_new)\n",
        "\n",
        "test_score =svc_kernel.score(T4_X.iloc[:,:-1], T4_y)\n",
        "\n",
        "print('Train accuracy:',train_score)\n",
        "print('Test accuracy:',test_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDKe1-DHSFgl",
        "outputId": "988c464c-db6c-4c8b-a156-5034bab7cb73"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.9158163265306123\n",
            "Test accuracy: 0.585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(j)}$"
      ],
      "metadata": {
        "id": "zsP1EWQaYWJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=[[] for i in range(7)]\n",
        "y_train=[[] for i in range(7)]\n",
        "x_test=[[] for i in range(7)]\n",
        "y_test=[[] for i in range(7)]\n",
        "kernel={}\n",
        "for i in range(7):\n",
        "  x_train[i]=T3_X[T3_y==i+1].iloc[:,:-1]\n",
        "  y_train[i]=T3_X[T3_y==i+1].iloc[:,-1]\n",
        "  x_test[i]=T4_X[T4_y==i+1].iloc[:,:-1]\n",
        "  y_test[i]=T4_X[T4_y==i+1].iloc[:,-1]\n",
        "  pipeline = make_pipeline(KernelRidge(kernel='rbf'))\n",
        "  param_range = np.linspace(0.1,10,20)\n",
        "  train_scores, val_scores = validation_curve(estimator=pipeline, X=x_train[i], y=y_train[i], cv=5,n_jobs=-1, param_name='kernelridge__gamma', param_range=param_range)\n",
        "  #print('\\n \\n \\n for class',i+1)\n",
        "  #print('train scores:',train_scores)\n",
        "  #print('val scores:',val_scores)\n",
        "\n",
        "  print('Printing more details of scores for each alpha:')\n",
        "  for j in range(len(param_range)):\n",
        "    print('alpha:', param_range[j])\n",
        "    print('train scores:', train_scores[j])\n",
        "    print('val scores:', val_scores[j])\n",
        "    print('**************************')\n",
        "  avg_train_scores = np.mean(train_scores,axis=1)\n",
        "  avg_val_scores = np.mean(val_scores,axis=1)\n",
        "  print('average train scores :',avg_train_scores)\n",
        "  print('average val scores :',avg_val_scores)\n",
        "  best_alpha = param_range[np.argmax(avg_val_scores)]\n",
        "  print('best_hyper_parameter from 5 fold CV:',best_alpha)\n",
        "  kernel[i+1] = KernelRidge(kernel='rbf',gamma=best_alpha)\n",
        "  kernel[i+1].fit(x_train[i], y_train[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWxpMR97YaAs",
        "outputId": "623497a5-cdfe-4326-fb21-500cb596a3bc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.47529665 0.45845749 0.44767129 0.403782   0.4990898 ]\n",
            "val scores: [-0.02440624 -0.23930199  0.26949646  0.25097852 -0.02818372]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.80031409 0.78021753 0.76167428 0.75949411 0.77740419]\n",
            "val scores: [0.10773436 0.24918868 0.8100334  0.3702986  0.28615916]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.82713044 0.79025971 0.77311333 0.77847627 0.78224713]\n",
            "val scores: [0.05643585 0.25274359 0.84990529 0.34067031 0.34410599]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.82929316 0.79012359 0.77241754 0.77938377 0.77934629]\n",
            "val scores: [0.03311726 0.12386855 0.83457172 0.31737374 0.35635919]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.82781096 0.78880469 0.77085813 0.77838184 0.77665096]\n",
            "val scores: [0.02072177 0.00437217 0.80401109 0.29601076 0.35517881]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.82553602 0.78736458 0.76948432 0.77730806 0.77434044]\n",
            "val scores: [ 0.0133278  -0.09326818  0.76892451  0.27599833  0.35055447]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.82299866 0.7859608  0.76823544 0.77625647 0.77219387]\n",
            "val scores: [ 0.00852782 -0.17646001  0.73299792  0.25724273  0.34492465]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.82035008 0.78460393 0.76704139 0.77520885 0.77013879]\n",
            "val scores: [ 0.00520932 -0.24961185  0.69763116  0.23965761  0.33878651]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.81766183 0.78328723 0.76588459 0.77417217 0.7681786 ]\n",
            "val scores: [ 0.00280793 -0.31454821  0.66337872  0.22316892  0.33221428]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.81497855 0.7820071  0.76476856 0.77316218 0.76633327]\n",
            "val scores: [ 0.00101516 -0.37218934  0.6304634   0.20771966  0.32522114]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.81233005 0.78076332 0.76369998 0.7721913  0.76461831]\n",
            "val scores: [-3.50254601e-04 -4.23256719e-01  5.98969692e-01  1.93262298e-01\n",
            "  3.17829932e-01]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.80973627 0.77955703 0.76268303 0.77126599 0.76304085]\n",
            "val scores: [-0.00140277 -0.46845407  0.56891846  0.17975215  0.31007903]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.80721023 0.77838948 0.7617189  0.77038786 0.76160093]\n",
            "val scores: [-0.00221964 -0.5084751   0.54029727  0.16714425  0.30201723]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.80476019 0.7772615  0.76080658 0.7695555  0.76029382]\n",
            "val scores: [-0.00285592 -0.54397615  0.51307379  0.15539249  0.29369872]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.80239108 0.77617345 0.75994385 0.76876591 0.75911199]\n",
            "val scores: [-0.00335234 -0.57555399  0.48720281  0.14444994  0.28517947]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.80010554 0.77512522 0.75912796 0.76801553 0.75804642]\n",
            "val scores: [-0.00373985 -0.60373547  0.46263066  0.13426942  0.27651484]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.79790461 0.77411636 0.75835607 0.76730071 0.75708761]\n",
            "val scores: [-0.00404232 -0.62897649  0.4392983   0.12480423  0.26775786]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.79578818 0.77314614 0.75762545 0.76661811 0.75622605]\n",
            "val scores: [-0.0042783  -0.65166646  0.41714378  0.11600873  0.25895816]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.79375536 0.77221367 0.75693363 0.76596475 0.7554526 ]\n",
            "val scores: [-0.0044623  -0.6721355   0.39610401  0.10783875  0.25016127]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.79180471 0.77131794 0.75627836 0.76533806 0.75475868]\n",
            "val scores: [-0.00460568 -0.6906625   0.37611626  0.10025197  0.2414082 ]\n",
            "**************************\n",
            "average train scores : [0.45685945 0.77582084 0.79024538 0.79011287 0.78850132 0.78680669\n",
            " 0.78512905 0.78346861 0.78183689 0.78024993 0.77872059 0.77725663\n",
            " 0.77586148 0.77453552 0.77327726 0.77208413 0.77095307 0.76988079\n",
            " 0.768864   0.76789955]\n",
            "average val scores : [0.04571661 0.36468284 0.36877221 0.33305809 0.29605892 0.26310739\n",
            " 0.23344662 0.20633455 0.18140433 0.158446   0.13729099 0.11777856\n",
            " 0.0997528  0.08306659 0.06758518 0.05318792 0.03976832 0.02723318\n",
            " 0.01550125 0.00450165]\n",
            "best_hyper_parameter from 5 fold CV: 1.142105263157895\n",
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.33019745 0.37557503 0.52699622 0.45289584 0.30993215]\n",
            "val scores: [  0.05127177  -0.02840887  -2.042537   -11.09310326   0.30277898]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.6968901  0.71215457 0.80956188 0.78919766 0.71114542]\n",
            "val scores: [ 0.4653622   0.2932722  -1.26832723 -7.9897384   0.51318154]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.74259869 0.76068505 0.82130073 0.81729093 0.76181222]\n",
            "val scores: [ 0.48892958  0.29099873 -0.95320567 -7.43804286  0.45058032]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.75878998 0.78028659 0.81626909 0.82027784 0.78045076]\n",
            "val scores: [ 0.4715215   0.25621815 -0.73655384 -6.97398716  0.3934509 ]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.76551287 0.78859934 0.80929785 0.81777357 0.78858808]\n",
            "val scores: [ 0.44366941  0.22329404 -0.59840271 -6.66688282  0.3433148 ]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.76818296 0.79187735 0.80301149 0.81362765 0.79239177]\n",
            "val scores: [ 0.4145516   0.19592485 -0.51552089 -6.45945236  0.29903946]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.7689262  0.79275575 0.79781801 0.80912006 0.79416877]\n",
            "val scores: [ 0.38718108  0.17349784 -0.46895917 -6.31325242  0.26043236]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.76872002 0.79243786 0.79361592 0.80476918 0.79488024]\n",
            "val scores: [ 0.36236498  0.1550376  -0.44562556 -6.20832658  0.22735964]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.76805383 0.79151446 0.79020846 0.80078348 0.79497248]\n",
            "val scores: [ 0.34011478  0.13971462 -0.43687089 -6.13362733  0.19944432]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.76718413 0.79029486 0.78741375 0.79722725 0.79468014]\n",
            "val scores: [ 0.32018926  0.12686677 -0.43707304 -6.08200843  0.1761203 ]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.76624817 0.78894925 0.7850876  0.79409637 0.79414175]\n",
            "val scores: [ 0.30229508  0.11597043 -0.44260638 -6.04818043  0.15675111]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.76531954 0.78757418 0.78312141 0.79135634 0.79344634]\n",
            "val scores: [ 0.28615377  0.10661339 -0.45114626 -6.02795404  0.14071613]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.76443682 0.78622489 0.78143457 0.78896173 0.7926541 ]\n",
            "val scores: [ 0.27151994  0.09847236 -0.46121219 -6.01795541  0.12745507]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.7636189  0.78493236 0.7799672  0.78686586 0.79180667]\n",
            "val scores: [ 0.25818314  0.09129447 -0.47187109 -6.01548803  0.11648404]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.76287344 0.78371298 0.77867446 0.78502522 0.79093306]\n",
            "val scores: [ 0.24596487  0.08488214 -0.48254501 -6.01843099  0.1073959 ]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.76220163 0.78257416 0.7775224  0.78340129 0.7900534 ]\n",
            "val scores: [ 0.23471454  0.07908103 -0.49288635 -6.02514517  0.09985338]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.76160102 0.7815178  0.776485   0.78196087 0.78918142]\n",
            "val scores: [ 0.22430547  0.07377056 -0.50269668 -6.0343851   0.09357961]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.76106717 0.78054246 0.77554211 0.78067581 0.7883263 ]\n",
            "val scores: [ 0.21463122  0.06885638 -0.51187365 -6.04521942  0.08834846]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.76059462 0.7796447  0.7746779  0.77952247 0.78749394]\n",
            "val scores: [ 0.20560242  0.06426466 -0.52037618 -6.05696249  0.08397563]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.76017757 0.77882001 0.77387986 0.77848108 0.7866879 ]\n",
            "val scores: [ 0.19714391  0.05993754 -0.52820155 -6.06911773  0.080311  ]\n",
            "**************************\n",
            "average train scores : [0.39911934 0.74378993 0.78073752 0.79121485 0.79395434 0.79381825\n",
            " 0.79255776 0.79088464 0.78910654 0.78736003 0.78570463 0.78416356\n",
            " 0.78274242 0.7814382  0.78024383 0.77915057 0.77814922 0.77723077\n",
            " 0.77638673 0.77560928]\n",
            "average val scores : [-2.56199967 -1.59724994 -1.43214798 -1.31787009 -1.25100146 -1.21309147\n",
            " -1.19222006 -1.18183798 -1.1782449  -1.17918103 -1.18315404 -1.1891234\n",
            " -1.19634404 -1.2042795  -1.21254662 -1.22087651 -1.22908523 -1.2370514\n",
            " -1.24469919 -1.25198537]\n",
            "best_hyper_parameter from 5 fold CV: 4.268421052631579\n",
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.29641005 0.19773454 0.19429862 0.14596717 0.24178212]\n",
            "val scores: [-0.25068189  0.02602445 -0.10568214  0.18881439 -0.1527849 ]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.50312705 0.44130786 0.42600686 0.40654021 0.47907296]\n",
            "val scores: [-0.31608973  0.01430684 -0.13878514  0.09906113 -0.17172888]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.57960911 0.52336471 0.50724358 0.50940734 0.56241733]\n",
            "val scores: [-0.27715187  0.03766082 -0.09063303  0.05411767 -0.14355931]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.61845527 0.56747115 0.54714676 0.56399865 0.60293199]\n",
            "val scores: [-0.23789444  0.03970185 -0.05095035  0.02738296 -0.11022245]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.64238297 0.59452542 0.57192055 0.59795318 0.62769265]\n",
            "val scores: [-0.20505012  0.03541922 -0.02122851  0.01184595 -0.08582207]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.65807935 0.6124912  0.58935124 0.62044424 0.64447333]\n",
            "val scores: [-0.17883275  0.02864972 -0.0010825   0.00307046 -0.0702273 ]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.66890351 0.62533295 0.60241032 0.63603694 0.65639751]\n",
            "val scores: [-0.15801431  0.02030708  0.01201478 -0.00144197 -0.0608021 ]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.67676348 0.63511426 0.61252879 0.64731389 0.66509019]\n",
            "val scores: [-0.14149848  0.01088188  0.02048349 -0.00326686 -0.05527738]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.68276712 0.64293206 0.62054742 0.65580311 0.67154027]\n",
            "val scores: [-0.1284128   0.000861    0.02600886 -0.00344751 -0.05211232]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.68756821 0.64939346 0.6270282  0.66243461 0.67640083]\n",
            "val scores: [-0.11804352 -0.00927641  0.02965102 -0.00267003 -0.05032653]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.69155901 0.6548559  0.63236949 0.66778838 0.68012093]\n",
            "val scores: [-0.1098021  -0.01912256  0.0320588  -0.00137706 -0.0493118 ]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.69497916 0.65954599 0.63685932 0.67223492 0.68301591]\n",
            "val scores: [-0.103209   -0.02837561  0.03363055  0.00015116 -0.04869769]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.69797821 0.66361835 0.64070718 0.6760169  0.68531009]\n",
            "val scores: [-0.09788042 -0.03684154  0.03461497  0.0017409  -0.04826352]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.70065213 0.66718535 0.64406575 0.67929755 0.68716442]\n",
            "val scores: [-0.09351466 -0.04441784  0.03517098  0.00328762 -0.04788205]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.70306477 0.67033261 0.64704663 0.68218967 0.68869514]\n",
            "val scores: [-0.08987819 -0.0510715   0.03540297  0.0047314  -0.04748369]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.70526043 0.67312757 0.64973181 0.68477331 0.68998664]\n",
            "val scores: [-0.0867927  -0.05681792  0.03538161  0.00604086 -0.04703401]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.70727134 0.67562451 0.65218183 0.68710681 0.69110043]\n",
            "val scores: [-0.0841235  -0.06170355  0.03515633  0.00720265 -0.04651952]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.70912202 0.6778678  0.65444176 0.6892337  0.69208151]\n",
            "val scores: [-0.0817699  -0.06579287  0.03476297  0.00821467 -0.04593883]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.71083196 0.679894   0.65654545 0.69118718 0.69296288]\n",
            "val scores: [-0.07965714 -0.069159    0.03422841  0.00908152 -0.04529715]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.71241711 0.6817335  0.65851849 0.69299307 0.69376879]\n",
            "val scores: [-0.07773013 -0.07187748  0.03357358  0.00981169 -0.04460291]\n",
            "**************************\n",
            "average train scores : [0.2152385  0.45121099 0.53640841 0.58000076 0.60689495 0.62496787\n",
            " 0.63781625 0.64736212 0.654718   0.66056506 0.66533874 0.66932706\n",
            " 0.67272615 0.67567304 0.67826577 0.68057595 0.68265698 0.68454936\n",
            " 0.68628429 0.68788619]\n",
            "average val scores : [-0.05886202 -0.10264715 -0.08391314 -0.06639648 -0.05296711 -0.04368447\n",
            " -0.0375873  -0.03373547 -0.03142055 -0.03013309 -0.02951094 -0.02930012\n",
            " -0.02932592 -0.02947119 -0.0296598  -0.02984443 -0.02999752 -0.03010479\n",
            " -0.03016067 -0.03016505]\n",
            "best_hyper_parameter from 5 fold CV: 5.831578947368421\n",
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.16157844 0.17228707 0.12813667 0.11979676 0.19023174]\n",
            "val scores: [-0.044208   -0.25976117  0.00388504  0.09852552 -0.05949699]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.37662026 0.34748897 0.30616486 0.29612239 0.35062037]\n",
            "val scores: [-0.21104091 -0.34886393  0.05674305  0.10002953 -0.10360769]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.45170585 0.42826788 0.40968308 0.38499445 0.43593403]\n",
            "val scores: [-0.19597174 -0.36382149  0.02055339  0.09421743 -0.11194261]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.50413407 0.48214334 0.4772291  0.44418421 0.49475391]\n",
            "val scores: [-1.54986494e-01 -3.35836461e-01 -5.72586403e-05  9.91026240e-02\n",
            " -1.02818564e-01]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.54213243 0.52023346 0.52284796 0.4853487  0.53543577]\n",
            "val scores: [-0.1242309  -0.30095821 -0.01148254  0.10501942 -0.08755789]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.56975964 0.54803352 0.55510426 0.51553727 0.56458882]\n",
            "val scores: [-0.10203974 -0.27023459 -0.01998769  0.10979603 -0.07272462]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.59032914 0.56905449 0.57880778 0.53872619 0.58630502]\n",
            "val scores: [-0.08519396 -0.24569492 -0.02721722  0.11290924 -0.06049232]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.60612928 0.58550879 0.59685522 0.55718197 0.60308424]\n",
            "val scores: [-0.07186486 -0.22680174 -0.03336938  0.11453806 -0.05117187]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.61863827 0.5987719  0.6110361  0.57227873 0.61646677]\n",
            "val scores: [-0.06105151 -0.21239149 -0.03844454  0.1150155  -0.04441586]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.62880319 0.609715   0.62247983 0.58490188 0.62742237]\n",
            "val scores: [-0.05214009 -0.20131849 -0.04249163  0.11463434 -0.03970375]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.63724047 0.61890906 0.63191981 0.59564797 0.63658064]\n",
            "val scores: [-0.04470781 -0.1926494  -0.04561249  0.11361281 -0.03653199]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.64436286 0.62674373 0.63984833 0.60493258 0.64436493]\n",
            "val scores: [-0.03844262 -0.18568448 -0.0479326   0.11210725 -0.03447831]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.65045653 0.6334958  0.64660708 0.61305359 0.65107045]\n",
            "val scores: [-0.03310722 -0.17992066 -0.0495791   0.11023093 -0.03321245]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.6557272  0.63936924 0.65244087 0.62023016 0.65691031]\n",
            "val scores: [-0.0285191  -0.17500386 -0.05066903  0.10806854 -0.03248633]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.66032782 0.64451912 0.65753005 0.62662749 0.66204323]\n",
            "val scores: [-0.02453713 -0.17068742 -0.05130468  0.10568578 -0.03211843]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.66437534 0.64906633 0.66201071 0.63237291 0.66659066]\n",
            "val scores: [-0.02105141 -0.1668002  -0.05157288  0.10313515 -0.0319785 ]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.66796123 0.65310697 0.6659877  0.63756647 0.67064761]\n",
            "val scores: [-0.0179757  -0.16322362 -0.05154611  0.10045964 -0.03197466]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.67115831 0.6567186  0.66954318 0.64228819 0.67428981]\n",
            "val scores: [-0.0152416  -0.15987548 -0.05128439  0.09769485 -0.03204325]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.67402526 0.65996458 0.67274248 0.64660294 0.67757851]\n",
            "val scores: [-0.01279423 -0.15669885 -0.05083721  0.09487054 -0.03214108]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.67660994 0.66289708 0.67563823 0.65056399 0.68056384]\n",
            "val scores: [-0.01058909 -0.15365433 -0.05024532  0.09201158 -0.03223965]\n",
            "**************************\n",
            "average train scores : [0.15440613 0.33540337 0.42211706 0.48048893 0.52119966 0.5506047\n",
            " 0.57264453 0.5897519  0.60343835 0.61466445 0.62405959 0.63205049\n",
            " 0.63893669 0.64493556 0.65020954 0.65488319 0.659054   0.66279962\n",
            " 0.66618275 0.66925462]\n",
            "average val scores : [-0.05221112 -0.10134799 -0.111393   -0.09891923 -0.08384202 -0.07103812\n",
            " -0.06113784 -0.05373396 -0.04825758 -0.04420392 -0.04117777 -0.03888615\n",
            " -0.0371177  -0.03572196 -0.03459238 -0.03365357 -0.03285209 -0.03214997\n",
            " -0.03152016 -0.03094336]\n",
            "best_hyper_parameter from 5 fold CV: 10.0\n",
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.12173178 0.11720038 0.11016003 0.12031264 0.11486927]\n",
            "val scores: [-0.08308625 -0.02400883  0.05030283 -0.0546012   0.03515047]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.24603701 0.26103816 0.27817628 0.28400048 0.28608148]\n",
            "val scores: [-0.03770475 -0.0255672  -0.06523107 -0.14092355 -0.03008952]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.33720178 0.35560112 0.37057202 0.37449124 0.38494987]\n",
            "val scores: [ 0.0164158   0.00580793 -0.04365895 -0.14007732 -0.05105265]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.40684696 0.41759348 0.43297716 0.43060754 0.44717634]\n",
            "val scores: [ 0.03200378  0.01584379 -0.02238994 -0.12546524 -0.05016448]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.45638603 0.45868471 0.47637469 0.46804208 0.48977445]\n",
            "val scores: [ 0.0292464   0.02279723 -0.01232709 -0.10987774 -0.04634051]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.49190535 0.48779576 0.507855   0.49466794 0.52082247]\n",
            "val scores: [ 0.02320571  0.03109264 -0.00792394 -0.09482283 -0.04272815]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.51816146 0.50943679 0.53156074 0.51459182 0.54434879]\n",
            "val scores: [ 0.01816583  0.04058413 -0.00570278 -0.08117957 -0.03977122]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.53817562 0.52606473 0.54997936 0.53015146 0.56265084]\n",
            "val scores: [ 0.01472318  0.05044782 -0.00433965 -0.06942174 -0.03738556]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.55384738 0.53918312 0.56467356 0.54275124 0.57719877]\n",
            "val scores: [ 0.01260667  0.06003846 -0.00341786 -0.05963152 -0.03541017]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.56640424 0.54977746 0.57665875 0.55326347 0.5889908 ]\n",
            "val scores: [ 0.01144558  0.06896853 -0.00280953 -0.05167232 -0.03370998]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.57666562 0.55851608 0.58661375 0.5622457  0.59872319]\n",
            "val scores: [ 0.01092934  0.07704214 -0.00245959 -0.04532443 -0.03219554]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.58519526 0.56586147 0.59500574 0.5700649  0.60688954]\n",
            "val scores: [ 0.01082212  0.08418617 -0.00232668 -0.04035528 -0.03081639]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.59239145 0.57213923 0.60216608 0.5769703  0.61384491]\n",
            "val scores: [ 0.01095089  0.09040103 -0.00237213 -0.03654866 -0.02954831]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.59854218 0.57758273 0.60833685 0.58313678 0.61984866]\n",
            "val scores: [ 0.0111918   0.09572874 -0.00256019 -0.03371401 -0.02838208]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.60386004 0.58236243 0.61369985 0.58869129 0.62509324]\n",
            "val scores: [ 0.01145893  0.10023279 -0.00285923 -0.03168744 -0.0273159 ]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.60850478 0.58660524 0.61839482 0.59372905 0.62972371]\n",
            "val scores: [ 0.01169516  0.10398592 -0.00324221 -0.03032963 -0.02635084]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.61259848 0.59040746 0.62253145 0.59832369 0.63385106]\n",
            "val scores: [ 0.01186489  0.10706283 -0.00368651 -0.02952297 -0.0254886 ]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.6162358  0.59384341 0.62619726 0.60253376 0.63756135]\n",
            "val scores: [ 0.01194814  0.109536   -0.00417345 -0.02916856 -0.02473033]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.61949116 0.59697138 0.62946304 0.60640687 0.64092216]\n",
            "val scores: [ 0.01193604  0.11147349 -0.00468779 -0.02918354 -0.02407633]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.62242381 0.59983769 0.63238674 0.60998253 0.64398717]\n",
            "val scores: [ 0.0118273   0.1129379  -0.00521721 -0.02949868 -0.02352592]\n",
            "**************************\n",
            "average train scores : [0.11685482 0.27106668 0.36456321 0.4270403  0.46985239 0.5006093\n",
            " 0.52361992 0.5414044  0.55553081 0.56701895 0.57655287 0.58460338\n",
            " 0.59150239 0.59748944 0.60274137 0.60739152 0.61154243 0.61527432\n",
            " 0.61865092 0.62172359]\n",
            "average val scores : [-0.01524859 -0.05990322 -0.04251304 -0.03003442 -0.02330034 -0.01823532\n",
            " -0.01358072 -0.00919519 -0.00516288 -0.00155554  0.00159838  0.00430199\n",
            "  0.00657657  0.00845285  0.00996583  0.01115168  0.01204593  0.01268236\n",
            "  0.01309237  0.01330468]\n",
            "best_hyper_parameter from 5 fold CV: 10.0\n",
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.15820121 0.13252393 0.08651669 0.10809342 0.11417668]\n",
            "val scores: [-0.16485768 -0.30949587 -0.08171022 -0.07625838 -0.06200742]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.44480155 0.34096477 0.30840721 0.32352338 0.38543508]\n",
            "val scores: [-0.39531387 -0.2139314  -0.23414816 -0.01262041 -0.27021934]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.54414602 0.42538519 0.38653595 0.41963767 0.48155917]\n",
            "val scores: [-0.42125736 -0.12292234 -0.1990431  -0.00800161 -0.28668245]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.59526402 0.47425272 0.4415019  0.47125713 0.53134059]\n",
            "val scores: [-0.4140651  -0.06622316 -0.1639237  -0.00235784 -0.28445583]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.62602863 0.50755372 0.48324536 0.50445185 0.56208364]\n",
            "val scores: [-0.39658895 -0.03397742 -0.14918198  0.00898709 -0.27108804]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.64666623 0.53219714 0.51528334 0.52811905 0.58334705]\n",
            "val scores: [-0.37653736 -0.01641768 -0.14627663  0.02070273 -0.25271758]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.66172736 0.55152827 0.54041779 0.54628252 0.59928782]\n",
            "val scores: [-0.35674429 -0.00654473 -0.14835328  0.03103699 -0.23269084]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.67335054 0.56729911 0.56049945 0.56094916 0.61192317]\n",
            "val scores: [-0.33806304 -0.00048816 -0.15171232  0.03970445 -0.2126961 ]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.68266145 0.58051411 0.57680061 0.57319729 0.62233357]\n",
            "val scores: [-0.32065109  0.00377045 -0.15466462  0.04690429 -0.19353679]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.6903239  0.5918024  0.59023525 0.5836574  0.63114401]\n",
            "val scores: [-0.30446226  0.00723959 -0.15659922  0.05294946 -0.17556379]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.69676168 0.60158449 0.60146935 0.59272991 0.63873788]\n",
            "val scores: [-0.28941382  0.01038135 -0.1574256   0.0581224  -0.15890029]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.70225913 0.6101549  0.61099096 0.60068801 0.64536385]\n",
            "val scores: [-0.27542972  0.01337223 -0.15727293  0.06263537 -0.14355387]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.70701365 0.61772795 0.61916056 0.6077292  0.6511931 ]\n",
            "val scores: [-0.26244417  0.01625022 -0.15634026  0.0666344  -0.12947364]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.71116629 0.62446495 0.62624738 0.61400268 0.65635081]\n",
            "val scores: [-0.25039707  0.01899501 -0.15482843  0.07021593 -0.11658077]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.71482066 0.63049104 0.63245514 0.61962494 0.66093351]\n",
            "val scores: [-0.23923048  0.02156902 -0.15291308  0.07344319 -0.1047854 ]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.71805514 0.63590596 0.63794016 0.62468921 0.66501889]\n",
            "val scores: [-0.22888711  0.02393653 -0.15073733  0.07635874 -0.09399589]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.72093078 0.64079101 0.64282404 0.6292715  0.6686714 ]\n",
            "val scores: [-0.2193103   0.02607121 -0.1484127   0.07899289 -0.08412374]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.72349642 0.64521369 0.64720268 0.63343468 0.6719456 ]\n",
            "val scores: [-0.21044455  0.02795784 -0.1460234   0.08136907 -0.07508598]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.72579212 0.64923086 0.65115269 0.63723135 0.67488826]\n",
            "val scores: [-0.20223613  0.02959139 -0.14363121  0.08350693 -0.06680616]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.72785138 0.65289097 0.65473604 0.64070597 0.67753982]\n",
            "val scores: [-0.19463366  0.03097513 -0.14128016  0.08542411 -0.05921452]\n",
            "**************************\n",
            "average train scores : [0.11990239 0.3606264  0.4514528  0.50272327 0.53667264 0.56112256\n",
            " 0.57984875 0.59480429 0.6071014  0.61743259 0.62625666 0.63389137\n",
            " 0.6405649  0.64644642 0.65166506 0.65632187 0.66049775 0.66425861\n",
            " 0.66765906 0.67074484]\n",
            "average val scores : [-0.13886592 -0.22524664 -0.20758137 -0.18620513 -0.16836986 -0.15424931\n",
            " -0.14265923 -0.13265103 -0.12363555 -0.11528725 -0.10744719 -0.10004978\n",
            " -0.09307469 -0.08651906 -0.08038335 -0.07466501 -0.06935653 -0.06444541\n",
            " -0.05991504 -0.05574582]\n",
            "best_hyper_parameter from 5 fold CV: 10.0\n",
            "Printing more details of scores for each alpha:\n",
            "alpha: 0.1\n",
            "train scores: [0.17675305 0.27936767 0.18037352 0.24705247 0.18573613]\n",
            "val scores: [-0.08683262 -0.17782043 -0.22214226 -0.44150767 -0.06169439]\n",
            "**************************\n",
            "alpha: 0.6210526315789474\n",
            "train scores: [0.467582   0.51340385 0.4588412  0.46187464 0.4469226 ]\n",
            "val scores: [-0.18565737 -0.22247623 -0.23647209 -0.29219969 -0.19500269]\n",
            "**************************\n",
            "alpha: 1.142105263157895\n",
            "train scores: [0.57485828 0.60895926 0.57447473 0.57293561 0.5468271 ]\n",
            "val scores: [-0.15404014 -0.12868239 -0.21688747 -0.1783519  -0.09681016]\n",
            "**************************\n",
            "alpha: 1.6631578947368424\n",
            "train scores: [0.62835172 0.65875341 0.63823709 0.63448058 0.59741182]\n",
            "val scores: [-0.11683871 -0.06366786 -0.20157739 -0.12177474  0.00827217]\n",
            "**************************\n",
            "alpha: 2.18421052631579\n",
            "train scores: [0.65835023 0.68655189 0.67599323 0.67024982 0.62751881]\n",
            "val scores: [-0.08819971 -0.02654372 -0.20038199 -0.09963614  0.0753003 ]\n",
            "**************************\n",
            "alpha: 2.7052631578947373\n",
            "train scores: [0.677181   0.70382903 0.69991909 0.69272713 0.64822138]\n",
            "val scores: [-0.0661399  -0.00352725 -0.20357003 -0.0931062   0.1131443 ]\n",
            "**************************\n",
            "alpha: 3.2263157894736847\n",
            "train scores: [0.69022735 0.71567165 0.71601623 0.70787964 0.66387277]\n",
            "val scores: [-0.04861483  0.01290593 -0.20656194 -0.09244573  0.13284537]\n",
            "**************************\n",
            "alpha: 3.747368421052632\n",
            "train scores: [0.69998007 0.72440426 0.72735461 0.71869128 0.67635013]\n",
            "val scores: [-0.03451022  0.02584176 -0.20797266 -0.09359275  0.14161385]\n",
            "**************************\n",
            "alpha: 4.268421052631579\n",
            "train scores: [0.70766851 0.73118384 0.73562953 0.72676649 0.68658984]\n",
            "val scores: [-0.02311412  0.03650196 -0.20762214 -0.09501308  0.14385389]\n",
            "**************************\n",
            "alpha: 4.7894736842105265\n",
            "train scores: [0.71394639 0.73664127 0.74183977 0.73302035 0.69514283]\n",
            "val scores: [-0.01387862  0.04543576 -0.20571845 -0.09617907  0.14224406]\n",
            "**************************\n",
            "alpha: 5.310526315789474\n",
            "train scores: [0.71919212 0.74114971 0.74660438 0.7380032  0.7023786 ]\n",
            "val scores: [-0.00635853  0.0529571  -0.2025631  -0.09695297  0.13841562]\n",
            "**************************\n",
            "alpha: 5.831578947368421\n",
            "train scores: [0.72364455 0.74494545 0.75032377 0.74206344 0.70856471]\n",
            "val scores: [-1.97783008e-04  5.92899311e-02 -1.98451316e-01 -9.73469193e-02\n",
            "  1.33363371e-01]\n",
            "**************************\n",
            "alpha: 6.352631578947369\n",
            "train scores: [0.72746649 0.7481867  0.75326675 0.74543215 0.71390231]\n",
            "val scores: [ 0.00487993  0.06461389 -0.19364239 -0.09742727  0.1276941 ]\n",
            "**************************\n",
            "alpha: 6.873684210526316\n",
            "train scores: [0.73077585 0.75098425 0.75561981 0.7482688  0.71854548]\n",
            "val scores: [ 0.00908355  0.06907901 -0.18835454 -0.0972745   0.12177669]\n",
            "**************************\n",
            "alpha: 7.394736842105264\n",
            "train scores: [0.73366183 0.75341859 0.75751609 0.75068698 0.7226135 ]\n",
            "val scores: [ 0.01256864  0.0728115  -0.18276763 -0.09696582  0.11583307]\n",
            "**************************\n",
            "alpha: 7.915789473684211\n",
            "train scores: [0.73619399 0.75555007 0.75905304 0.75276968 0.72619968]\n",
            "val scores: [ 0.01545048  0.07591741 -0.17702793 -0.09656802  0.10999371]\n",
            "**************************\n",
            "alpha: 8.436842105263159\n",
            "train scores: [0.73842772 0.75742511 0.76030349 0.75457878 0.72937775]\n",
            "val scores: [ 0.01781506  0.07848579 -0.17125282 -0.09613519  0.10433183]\n",
            "**************************\n",
            "alpha: 8.957894736842105\n",
            "train scores: [0.74040779 0.75908028 0.76132289 0.75616128 0.73220665]\n",
            "val scores: [ 0.01972764  0.08059151 -0.16553517 -0.09570893  0.09888487]\n",
            "**************************\n",
            "alpha: 9.478947368421053\n",
            "train scores: [0.74217079 0.76054501 0.76215411 0.75755342 0.73473407]\n",
            "val scores: [ 0.02123906  0.0822978  -0.15994707 -0.09531967  0.09366794]\n",
            "**************************\n",
            "alpha: 10.0\n",
            "train scores: [0.74374692 0.76184339 0.76283074 0.7587836  0.73699909]\n",
            "val scores: [ 0.02239026  0.08365838 -0.15454318 -0.09498842  0.08868252]\n",
            "**************************\n",
            "average train scores : [0.21385657 0.46972486 0.575611   0.63144692 0.6637328  0.68437553\n",
            " 0.69873353 0.70935607 0.71756764 0.72411812 0.7294656  0.73390838\n",
            " 0.73765088 0.74083884 0.7435794  0.74595329 0.74802257 0.74983578\n",
            " 0.75143148 0.75284075]\n",
            "average val scores : [-0.19799947 -0.22636161 -0.15495441 -0.09911731 -0.06789225 -0.05063982\n",
            " -0.04037424 -0.033724   -0.0290787  -0.02561926 -0.02290038 -0.02066854\n",
            " -0.01877635 -0.01713796 -0.01570405 -0.01444687 -0.01335107 -0.01240802\n",
            " -0.01161239 -0.01096009]\n",
            "best_hyper_parameter from 5 fold CV: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(k)}$"
      ],
      "metadata": {
        "id": "bGKL5VazqDTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train=[]\n",
        "y_train=[]\n",
        "label=svc_kernel.predict(T3_X.iloc[:,:-1])\n",
        "for i in range(1,8):\n",
        "  if sum(label==i)>0:\n",
        "    y_pred_train.extend(list(kernel[i].predict(T3_X[label==i].iloc[:,:-1])))\n",
        "    y_train.extend(list(T3_X[label==i].iloc[:,-1]))"
      ],
      "metadata": {
        "id": "SmJhk48haFd4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"root mean square error for training data t3 is \", sqrt(mean_squared_error(y_train, y_pred_train)))\n",
        "print(\"R^2 for training data set(T3) is \",r2_score(y_train, y_pred_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ-Ye2AjaIne",
        "outputId": "18f68ab4-7f9e-4a0a-c84f-c6db54c8fb27"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root mean square error for training data t3 is  0.6907600198011522\n",
            "R^2 for training data set(T3) is  0.5212620381866099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test=[]\n",
        "y_test=[]\n",
        "label=svc_kernel.predict(T4_X.iloc[:,:-1])\n",
        "for i in range(1,8):\n",
        "  if sum(label==i)>0:\n",
        "    y_pred_test.extend(list(kernel[i].predict(T4_X[label==i].iloc[:,:-1])))\n",
        "    y_test.extend(list(T4_X[label==i].iloc[:,-1]))"
      ],
      "metadata": {
        "id": "M9DjInmRaOHP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"root mean square error for test data t4 is \", sqrt(mean_squared_error(y_test, y_pred_test)))\n",
        "print('R^2 for test dataset(T4) is',r2_score(y_test,y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7JEWzwsaQ95",
        "outputId": "23c7e81f-ceeb-43c2-8efc-090402f92e05"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root mean square error for test data t4 is  1.0164141428739681\n",
            "R^2 for test dataset(T4) is -0.057070316187038506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\Large\\textbf{Part(l)}$"
      ],
      "metadata": {
        "id": "ymopuwuorrZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In part (f), r_2 value is higher while in part (k), rmse value is higher.\n",
        "\n",
        "* The two-stage approach of classification-followed-by-regression is useful when the target variable has a complex relationship with the predictor variables, and a single regression model cannot adequately capture the relationship.\n",
        "In such cases, the two-stage approach first classifies the data into different groups based on a categorical variable, and then fits separate regression models for each group. This approach can capture the unique relationships between the predictor variables and the target variable within each group, resulting in more accurate predictions.\n",
        "\n",
        "* On the other hand, a simple regression approach on the full dataset assumes a single relationship between the predictor variables and the target variable, which may not be accurate for all observations in the dataset. This approach may result in a less accurate model that does not capture the nuances of the data."
      ],
      "metadata": {
        "id": "n577p7E63KSc"
      }
    }
  ]
}